{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right_list_shape: (159, 1)\n",
      "left_list_shape: (159, 1)\n"
     ]
    }
   ],
   "source": [
    "#導入所需套件\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "path='Train_DataSet\\\\'\n",
    "file_path=pd.read_excel(\"Train_Quality_DataSet\\\\quality_size.xlsx\")['key']       #將file夾名稱放進file_path\n",
    "right_list=list()\n",
    "left_list=list()\n",
    "\n",
    "#使用for迴圈設定完整的.xlsx路徑，讀進raw data後放入right_list及left_list\n",
    "for i in file_path:\n",
    "    dat_path=path+\"file_\"+str(i)\n",
    "#     print(dat_path)\n",
    "    excel_path=os.listdir(dat_path)\n",
    "    for j in excel_path:\n",
    "        if j=='pressure.xlsx':\n",
    "            #print(dat_path+\"\\\\\"+j)\n",
    "            A=pd.read_excel(dat_path+\"\\\\\"+j)\n",
    "            A=A.drop(['Unnamed: 0','TimeStamp'], axis=1)\n",
    "#               print(A.shape)                        \n",
    "            for k in A:\n",
    "                if k=='pressure_right':\n",
    "                    right_list.append([A[k]])\n",
    "                elif k=='pressure_left':\n",
    "                    left_list.append([A[k]])\n",
    "print(\"right_list_shape:\",str(np.array(right_list).shape))\n",
    "print(\"left_list_shape:\",str(np.array(left_list).shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right_list_shape: (159, 1, 7443)\n",
      "right_list_shape: (159, 7443)\n",
      "left_list_shape: (159, 1, 7443)\n",
      "left_list_shape: (159, 7443)\n"
     ]
    }
   ],
   "source": [
    "#導入所需套件\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "#使用pad_sequences進行data補值，並轉換list維度\n",
    "cnt=0\n",
    "for i in right_list:\n",
    "    right_list[cnt]=sequence.pad_sequences(i,dtype='float64',maxlen=7443)          \n",
    "    cnt+=1\n",
    "print(\"right_list_shape:\",str(np.array(right_list).shape))                                  \n",
    "right_list = np.reshape(right_list,(-1,7443))                           #三維轉二維\n",
    "print(\"right_list_shape:\",str(np.array(right_list).shape))              \n",
    "\n",
    "cnt=0\n",
    "for i in left_list:\n",
    "    left_list[cnt]=sequence.pad_sequences(i,dtype='float64',maxlen=7443)          \n",
    "    cnt+=1\n",
    "print(\"left_list_shape:\",str(np.array(left_list).shape))                                  \n",
    "left_list = np.reshape(left_list,(-1,7443))                           #三維轉二維\n",
    "print(\"left_list_shape:\",str(np.array(left_list).shape))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right_list[158]: [0.         0.         0.         ... 0.00929615 0.00929615 0.00929615]\n",
      "left_list[158]: [0.         0.         0.         ... 0.00837989 0.00837989 0.00837989]\n"
     ]
    }
   ],
   "source": [
    "#導入所需套件\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#對data進行正規化計算\n",
    "right_list=right_list/right_list.max()\n",
    "print(\"right_list[158]:\",right_list[158])\n",
    "\n",
    "left_list=left_list/left_list.max()\n",
    "print(\"left_list[158]:\",left_list[158])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right_labels: [3 3 3 3 3 4 3 4 3 3 3 3 3 4 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 4 3 3 3 3 3 3 3 3 4 3 4 3 4 3 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 4 3 3 3 3 3 3 3 3 4 3 3 3 3 3 3 4 3 4 3 3 4 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 4 4 3 3 3 3 3 3 3]\n",
      "left_labels: [3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 2 3 3 3 3 3 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 4 3 3 3 3 3 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "#導入所需套件\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "#讀進quality_class_type.xlsx\n",
    "path='Train_Quality_DataSet\\\\quality_class_type.xlsx'\n",
    "class_type=pd.read_excel(path)\n",
    "\n",
    "#labels設定\n",
    "num_of_samples=right_list.shape[0]\n",
    "right_labels=np.zeros((num_of_samples,),dtype='int64')\n",
    "left_labels=np.zeros((num_of_samples,),dtype='int64')\n",
    "\n",
    "for i in class_type:\n",
    "    cnt=0\n",
    "    if i=='right_ng_s':\n",
    "        for j in class_type[i]:\n",
    "            if j==1:\n",
    "                right_labels[cnt]=0\n",
    "            cnt+=1\n",
    "    elif i=='right_normal_s':\n",
    "        for j in class_type[i]:\n",
    "            if j==1:\n",
    "                right_labels[cnt]=1\n",
    "            cnt+=1\n",
    "    elif i=='right_best':\n",
    "        for j in class_type[i]:\n",
    "            if j==1:\n",
    "                right_labels[cnt]=2\n",
    "            cnt+=1\n",
    "    elif i=='right_normal_l':\n",
    "        for j in class_type[i]:\n",
    "            if j==1:\n",
    "                right_labels[cnt]=3\n",
    "            cnt+=1\n",
    "    elif i=='right_ng_l':\n",
    "        for j in class_type[i]:\n",
    "            if j==1:\n",
    "                right_labels[cnt]=4\n",
    "            cnt+=1\n",
    "            \n",
    "    elif i=='left_ng_s':\n",
    "        for j in class_type[i]:\n",
    "            if j==1:\n",
    "                left_labels[cnt]=0\n",
    "            cnt+=1\n",
    "    elif i=='left_normal_s':\n",
    "        for j in class_type[i]:\n",
    "            if j==1:\n",
    "                left_labels[cnt]=1\n",
    "            cnt+=1\n",
    "    elif i=='left_best':\n",
    "        for j in class_type[i]:\n",
    "            if j==1:\n",
    "                left_labels[cnt]=2\n",
    "            cnt+=1\n",
    "    elif i=='left_normal_l':\n",
    "        for j in class_type[i]:\n",
    "            if j==1:\n",
    "                left_labels[cnt]=3\n",
    "            cnt+=1\n",
    "    elif i=='left_ng_l':\n",
    "        for j in class_type[i]:\n",
    "            if j==1:\n",
    "                left_labels[cnt]=4\n",
    "            cnt+=1\n",
    "print(\"right_labels:\",right_labels)\n",
    "print(\"left_labels:\",left_labels)\n",
    "\n",
    "#使用shuffle對feature、labels進行亂數配對\n",
    "x_right,y_right=shuffle(right_list,right_labels,random_state=2)\n",
    "# x_right_train,x_right_test,y_right_train,y_right_test_=train_test_split(x_right,y_right,test_size=0.2,random_state=2)\n",
    "\n",
    "x_left,y_left=shuffle(left_list,left_labels,random_state=2)\n",
    "# x_left_train,x_left_test,y_left_train,y_left_test=train_test_split(x_left,y_left,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross val score: [0.81818182 0.9375     0.90625    0.90322581 0.93548387]\n",
      "Average Cross val score: 0.9001282991202346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 4 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross val score: [0.96875    0.96875    0.96875    0.90625    0.93548387]\n",
      "Average Cross val score: 0.9495967741935484\n"
     ]
    }
   ],
   "source": [
    "#導入所需套件\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#使用LinearRegression()訓練並預測\n",
    "model1=LogisticRegression(solver ='lbfgs',multi_class='auto',max_iter=2000,class_weight ={3:0.1,4:0.9},C=1e7)\n",
    "score1=cross_val_score(model1,x_right,y_right,cv=5)\n",
    "model1.fit(x_right,y_right)\n",
    "print(\"Cross val score:\",score1)    #[0.81818182 0.9375     0.90625    0.90322581 0.93548387]\n",
    "print(\"Average Cross val score:\",score1.mean())    #0.9001282991202346\n",
    "\n",
    "model2=LogisticRegression(solver ='lbfgs',multi_class='auto',max_iter=2000,class_weight ={2:0.2,3:0.1,4:0.7})\n",
    "score2=cross_val_score(model1,x_left,y_left,cv=5)\n",
    "model2.fit(x_left,y_left)\n",
    "print(\"Cross val score:\",score2)    #[0.96875    0.96875    0.96875    0.90625    0.93548387]\n",
    "print(\"Average Cross val score:\",score2.mean())   #0.9495967741935484"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['left_type.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#導入所需套件\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "#模型儲存\n",
    "joblib.dump(model1,'right_type.pkl')\n",
    "joblib.dump(model2,'left_type.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
